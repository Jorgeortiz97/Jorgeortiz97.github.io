---
layout: post
title: "Final Degree Project"
subtitle: "Design, implementation and evaluation of a convolutional neural network for different platforms"
date: 2019-06-10 15:00:00 -0400
background: '/img/posts/01.jpg'
topic: MachineLearning, FPGA
---

# Description

The main objective of this work is the design, implementation and evaluation of a machine learning algorithm in an FPGA system; including other computing platforms such as CPU or GPU.

* **Author**: Jorge Ortiz Escribano.
* **Supervisor**: Juan Luis Aragón Alcaraz.

This project has been presented as a Final Degree Project for the Computer Science degree from the University of Murcia. It has been endowed with a Collaboration Grant from the Spanish Ministry of Education and Culture (MEC).

<img src="/img/posts/01/MiLenet5.png" alt="Estructura de LeNet-5" width="750" height="180" />

## Implemented versions

The following versions have been implemented:
* **Sequential (CPU)** . Designed for a general-purpose computer. Written in C.
* **OpenMP (CPU)**. Designed for a general-purpose computer and written in C in combination with the OpenMP framework.
* **GPU**. Designed combining a general purpose computer and a graphics processing unit (GPU). Written in C using the Nvidia API: CUDA.
* **FPGA-HLS**. Synthesized from high level code (HLS). Written in C/C ++ using Vivado (SDSoC).
* **FPGA-Verilog**. Written directly using hardware description language (HDL); in particular, Verilog.

## Resources used
In this section, the resources that are used for the elaboration of this work are discussed, including both the software elements and the hardware platforms.

#### Software technologies

* **gcc:** GNU C Compiler. Version 6.5.0.
* **nvcc:** Nvidia C Compiler. Version V9.1.85.
* **OpenMP:** Version 11-2015.
* **GNU make:** Version 4.1.
* **Putty:** Version 0.7.
* **Git:** Version 2.17.1.
* **Likwid:** Version 4.3.3.
* **Vivado toolkit:** Version 2018.3. Including Vivado, Vivado HLS y SDSoC.

#### Hardware platforms
The versions implemented for general-purpose computers have been evaluated on a machine composed of two Intel Xeon E5-2667 v3 hexacores (NUMA architecture). In particular, the machine has the following hardware characteristics:

* Two processors Intel (R) Xeon E5-2667 v3. This is a total of 16 physical cores, each one of them working at 3.20 GHz, with 20 MB of cache and *hyperthreading*).
* 128 GB of RAM.

The accelerated version by GPU has been evaluated using a GeForce GTX 760 graphics card, which has the following characteristics:

* Kepler architecture.
* 192 CUDA *cores* (6 *Streaming Multiprocessors* or *SM* and 192 *Streaming Processors* per *SM*).
* 2 GB of GDDR5 RAM.

Regarding the reprogrammable hardware, the designs have been synthesized on a ZedBoard board, which incorporates the *System on a Chip* Zynq-7000. That SoC combines a Dual-core ARM Cortex™-A9 processor with a FPGA and 512 MB of DDR3 RAM. The ARM processor operates at a frequency of 667 MHz. The FPGA is composed of the following resources:

* 280 RAM blocks of 18 Kb (≈ 4.92 MB).
* 220 units DSP_48E.
* 106400 flip-flops.
* 53200 LUTs (* Look-Up Table *).

## Results

The percentage of success of the network is 95.5% in the case of the versions that use floating point (simple precision) as a data format. The versions that use fixed point instead get a slightly lower precision (95.45%).

The following chart shows the performance achieved by each platform (indicated as the number of digits that are recognized per second):

<img src="/img/posts/01/Performance.jpg" alt="Performance" width="750" height="475" />

The results obtained show that it is quite complicated to achieve the throughput offered by conventional platforms such as, for example, multicore CPU or GPU, by using FPGA systems. Although the GPU has the highest throughput rate, the best relation Performance/Power is achieved by some of the FPGA implementations, obtaining an improvement greater than 6 with respect to the GPU. The fixed-point HLS implementation is the one that obtains the best results for the FPGA. As expected, the use of a fixed point is a key factor when it comes to obtaining a better performance. The following graph shows the performance obtained in relation to energy consumption:

<img src="/img/posts/01/PerformancePower.jpg" alt="Performance/Power" width="750" height="475" />

## Source code

If you want to see the code, you can find it in this [GitHub repository](https://github.com/Jorgeortiz97/lenet5).